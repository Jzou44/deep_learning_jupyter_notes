{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a95f1e29-5235-4b10-bcf7-93af6686833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset train with sample number 90655\n",
      "dataset test with sample number 4310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 0: 100%|██████████| 11332/11332 [54:58<00:00,  3.44it/s, loss=0.00357681,MSE=0.00243489,RMSE=0.04812039,MAE=0.03388047,ABS_REL=0.03879489, DELTA1.02=0.41192950, DELTA1.05=0.75313748]  \n",
      "test epoch 0: 100%|██████████| 539/539 [02:15<00:00,  3.97it/s, loss=0.00346345,MSE=0.00243341,RMSE=0.04566022,MAE=0.03480058,ABS_REL=0.03938123, DELTA1.02=0.39687968, DELTA1.05=0.73574014]\n",
      "train epoch 1: 100%|██████████| 11332/11332 [54:00<00:00,  3.50it/s, loss=0.00265416,MSE=0.00180431,RMSE=0.04151762,MAE=0.02932507,ABS_REL=0.03359532, DELTA1.02=0.46572401, DELTA1.05=0.79867962] \n",
      "test epoch 1: 100%|██████████| 539/539 [02:15<00:00,  3.99it/s, loss=0.00299351,MSE=0.00205106,RMSE=0.04073735,MAE=0.03024330,ABS_REL=0.03457515, DELTA1.02=0.48265217, DELTA1.05=0.79656483]\n",
      "train epoch 2: 100%|██████████| 11332/11332 [53:59<00:00,  3.50it/s, loss=0.00172227,MSE=0.00116465,RMSE=0.03345234,MAE=0.02289120,ABS_REL=0.02605824, DELTA1.02=0.56913731, DELTA1.05=0.86648042] \n",
      "test epoch 2: 100%|██████████| 539/539 [02:16<00:00,  3.96it/s, loss=0.00262775,MSE=0.00177993,RMSE=0.03764294,MAE=0.02762484,ABS_REL=0.03165525, DELTA1.02=0.52370325, DELTA1.05=0.82394569]\n",
      "train epoch 3: 100%|██████████| 11332/11332 [54:17<00:00,  3.48it/s, loss=0.00125338,MSE=0.00085945,RMSE=0.02878651,MAE=0.01966392,ABS_REL=0.02231825, DELTA1.02=0.63189365, DELTA1.05=0.89761313] \n",
      "test epoch 3: 100%|██████████| 539/539 [02:15<00:00,  3.99it/s, loss=0.00255416,MSE=0.00170669,RMSE=0.03674892,MAE=0.02669278,ABS_REL=0.03065484, DELTA1.02=0.54261904, DELTA1.05=0.83096421]\n",
      "train epoch 4:  12%|█▏        | 1399/11332 [06:43<47:42,  3.47it/s, loss=0.00140656,MSE=0.00094892,RMSE=0.03032236,MAE=0.02061073,ABS_REL=0.02346263, DELTA1.02=0.61366862, DELTA1.05=0.88828504]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35473/2936733684.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35473/2936733684.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, epoch, optimizer)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train epoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_target\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torchvision.transforms.functional as ttf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "batch_size = 8\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class ResnetBackBone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResnetBackBone, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        self.input_pool = nn.Sequential(*list(resnet.children())[:4])\n",
    "        self.down_block_1, self.down_block_2, self.down_block_3, self.down_block_4 = \\\n",
    "            [block for block in resnet.children() if isinstance(block, nn.Sequential)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_pool(x)\n",
    "        x = self.down_block_1(x)\n",
    "        feat8 = self.down_block_2(x)\n",
    "        feat16 = self.down_block_3(feat8)\n",
    "        feat32 = self.down_block_4(feat16)\n",
    "        return feat8, feat16, feat32\n",
    "\n",
    "\n",
    "class CovBnRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1):\n",
    "        super(CovBnRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttentionRefinementModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(AttentionRefinementModule, self).__init__()\n",
    "        self.conv_1 = CovBnRelu(in_channels, out_channels)\n",
    "        self.conv_attention = nn.Conv2d(out_channels, out_channels, kernel_size=1, padding=0, bias=False)\n",
    "        self.bn_attention = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.conv_1(x)\n",
    "        atten = torch.mean(feat, dim=(2, 3), keepdim=True)\n",
    "        atten = self.conv_attention(atten)\n",
    "        atten = self.bn_attention(atten)\n",
    "        atten = torch.sigmoid(atten)\n",
    "        out = torch.mul(feat, atten)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ContextPath(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContextPath, self).__init__()\n",
    "        self.backbone = ResnetBackBone()\n",
    "        self.conv_avg = CovBnRelu(512, 128, kernel_size=1, stride=1, padding=0)\n",
    "        self.arm32 = AttentionRefinementModule(512, 128)\n",
    "        self.arm16 = AttentionRefinementModule(256, 128)\n",
    "        self.up32 = nn.Upsample(scale_factor=2.)\n",
    "        self.up16 = nn.Upsample(scale_factor=2.)\n",
    "        self.conv_head32 = CovBnRelu(128, 128)\n",
    "        self.conv_head16 = CovBnRelu(128, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat8, feat16, feat32 = self.backbone(x)\n",
    "        avg = torch.mean(feat32, dim=(2, 3), keepdim=True)\n",
    "        avg = self.conv_avg(avg)  # [1, 128, 1, 1]\n",
    "\n",
    "        feat32_arm = self.arm32(feat32)  # [1, 128, 15, 20]\n",
    "        feat32_sum = feat32_arm + avg\n",
    "        feat32_up = self.up32(feat32_sum)  # [1, 128, 30, 40]\n",
    "        feat32_up = self.conv_head32(feat32_up)  # [1, 128, 30, 40]\n",
    "\n",
    "        feat16_arm = self.arm16(feat16)  # [1, 128, 30, 40]\n",
    "        feat16_sum = feat16_arm + feat32_up\n",
    "        feat16_up = self.up16(feat16_sum)  # [1, 128, 60, 80]\n",
    "        feat16_up = self.conv_head16(feat16_up)  # [1, 128, 60, 80]\n",
    "        return feat16_up, feat32_up\n",
    "\n",
    "\n",
    "class SpatialPath(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialPath, self).__init__()\n",
    "        self.conv_1 = CovBnRelu(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.conv_2 = CovBnRelu(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv_3 = CovBnRelu(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv_out = CovBnRelu(64, 128, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.conv_1(x)\n",
    "        feat = self.conv_2(feat)\n",
    "        feat = self.conv_3(feat)\n",
    "        feat = self.conv_out(feat)\n",
    "        return feat  # [4, 128, 60, 80]\n",
    "\n",
    "\n",
    "class FeatureFusionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FeatureFusionModule, self).__init__()\n",
    "        self.conv_1 = CovBnRelu(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_atten = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn_atten = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, fsp, fcp):\n",
    "        feat = torch.cat([fsp, fcp], dim=1)\n",
    "        feat = self.conv_1(feat)\n",
    "        atten = torch.mean(feat, dim=(2, 3), keepdim=True)\n",
    "        atten = self.conv_atten(atten)\n",
    "        atten = self.bn_atten(atten)\n",
    "        atten = torch.sigmoid(atten)\n",
    "        feat_atten = torch.mul(feat, atten)\n",
    "        feat_out = feat_atten + feat\n",
    "        return feat_out\n",
    "\n",
    "\n",
    "class BiSeNetOutput(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, up_factor):\n",
    "        super(BiSeNetOutput, self).__init__()\n",
    "        self.conv = CovBnRelu(in_channels, mid_channels)\n",
    "        self.conv_out = nn.Conv2d(mid_channels, out_channels, kernel_size=1)\n",
    "        self.up = nn.Upsample(scale_factor=up_factor, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_out(x)\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BiSeNetV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiSeNetV1, self).__init__()\n",
    "        self.cp = ContextPath()\n",
    "        self.sp = SpatialPath()\n",
    "        self.ffm = FeatureFusionModule(256, 256)\n",
    "        self.conv_out_8 = BiSeNetOutput(256, 256, 1, up_factor=8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat_cp_8, feat_cp_16 = self.cp(x)\n",
    "        feat_sp_8 = self.sp(x)\n",
    "        feat_fuse = self.ffm(feat_sp_8, feat_cp_8)  # [4, 256, 60, 80]\n",
    "        feat_out = self.conv_out_8(feat_fuse)\n",
    "        return torch.exp(feat_out)\n",
    "\n",
    "\n",
    "class NyuDataset(Dataset):\n",
    "    def __init__(self, mode=\"train\"):\n",
    "        assert mode == \"train\" or mode == \"test\"\n",
    "        self.mode = mode\n",
    "        files = [str(x) for x in Path(\"./data\").glob(\"*.json\")]\n",
    "        train_files, test_files = train_test_split(files, test_size=0.05, random_state=0)\n",
    "        self.files = train_files if self.mode == \"train\" else test_files\n",
    "        self.dataset = []\n",
    "        for file_path in self.files:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                self.dataset.extend(json.load(f)[::5])\n",
    "        self.dataset_length = len(self.dataset)\n",
    "        print(f\"dataset {self.mode} with sample number {self.dataset_length}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def read_pgm(pgm_file_path):\n",
    "        with open(pgm_file_path, 'rb') as pgm_file:\n",
    "            p5, width, height, depth = pgm_file.readline().split()\n",
    "            assert p5 == b'P5'\n",
    "            assert depth == b'65535'\n",
    "            width, height = int(width), int(height)\n",
    "            data = np.fromfile(pgm_file, dtype='<u2', count=width * height)\n",
    "            data = data.reshape([height, width]).astype(np.uint32)\n",
    "            return Image.fromarray(data, mode=\"I\")\n",
    "\n",
    "    @staticmethod\n",
    "    def read_ppm(ppm_file_path):\n",
    "        with open(ppm_file_path, 'rb') as ppm_file:\n",
    "            p6, width, height, depth = ppm_file.readline().split()\n",
    "            assert p6 == b'P6'\n",
    "            assert depth == b'255'\n",
    "            width, height = int(width), int(height)\n",
    "            data = np.fromfile(ppm_file, dtype=np.uint8, count=width * height * 3)\n",
    "            data = data.reshape([height, width, 3])\n",
    "            return Image.fromarray(data, mode=\"RGB\")\n",
    "\n",
    "    def transform_fn(self, rgb, depth):\n",
    "        if self.mode == \"train\":\n",
    "            if np.random.uniform() < 0.5:\n",
    "                rgb = ttf.hflip(rgb)\n",
    "                depth = ttf.hflip(depth)\n",
    "\n",
    "            degree = np.random.uniform(-5.0, 5.0)\n",
    "            rgb = ttf.rotate(rgb, degree)\n",
    "            depth = ttf.rotate(depth, degree)\n",
    "\n",
    "            brightness = np.random.uniform(0.9, 1.1)\n",
    "            contrast = np.random.uniform(0.9, 1.1)\n",
    "            saturation = np.random.uniform(0.9, 1.1)\n",
    "            rgb = ttf.adjust_brightness(rgb, brightness)\n",
    "            rgb = ttf.adjust_contrast(rgb, contrast)\n",
    "            rgb = ttf.adjust_saturation(rgb, saturation)\n",
    "\n",
    "        rgb = ttf.to_tensor(rgb)\n",
    "        depth = ttf.to_tensor(depth)\n",
    "        rgb = torch.as_tensor(rgb, dtype=torch.float)\n",
    "        depth = torch.as_tensor(depth, dtype=torch.float)\n",
    "        depth /= 1000\n",
    "\n",
    "        rgb = ttf.normalize(rgb, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        return rgb, depth\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset[idx]\n",
    "        try:\n",
    "            rgb = self.read_ppm(sample[\"ppm\"])\n",
    "            depth = self.read_pgm(sample[\"pgm\"])\n",
    "            rgb, depth = self.transform_fn(rgb, depth)\n",
    "        except Exception as e:\n",
    "            rgb = torch.zeros([3, 480, 640])\n",
    "            depth = torch.zeros([1, 480, 640])\n",
    "        return rgb, depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_length\n",
    "\n",
    "\n",
    "def calc_error(depth_pred, depth_target):\n",
    "    error = {}\n",
    "    mask = torch.logical_and(torch.gt(depth_target, 1e-3), torch.lt(depth_target, 2))\n",
    "    depth_pred = depth_pred[mask]\n",
    "    depth_target = depth_target[mask]\n",
    "    n_valid_element = depth_target.shape[0] + 1e-4\n",
    "\n",
    "    diff_mat = torch.abs(depth_pred - depth_target)\n",
    "    rel_mat = torch.div(diff_mat, depth_target)\n",
    "    error[\"MSE\"] = torch.sum(torch.pow(diff_mat, 2)) / n_valid_element\n",
    "    error[\"RMSE\"] = torch.sqrt(error[\"MSE\"])\n",
    "    error['MAE'] = torch.sum(diff_mat) / n_valid_element\n",
    "    error['ABS_REL'] = torch.sum(rel_mat) / n_valid_element\n",
    "    y_over_z = torch.div(depth_target, depth_pred)\n",
    "    z_over_y = torch.div(depth_pred, depth_target)\n",
    "    max_ratio = torch.max(y_over_z, z_over_y)\n",
    "    error['DELTA1.02'] = torch.sum(max_ratio < 1.02) / float(n_valid_element)\n",
    "    error['DELTA1.05'] = torch.sum(max_ratio < 1.05) / float(n_valid_element)\n",
    "\n",
    "    error = {K: V.item() for K, V in error.items()}\n",
    "\n",
    "    error['loss'] = torch.mean(torch.pow(torch.log(depth_pred) - torch.log(depth_target), 2))\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "def train(model, dataloader, epoch, optimizer):\n",
    "    time.sleep(0.2)\n",
    "    model.train()\n",
    "    loss_count = deque([], maxlen=100)\n",
    "    pbar = tqdm(dataloader)\n",
    "    pbar.set_description(\"train epoch {}\".format(epoch))\n",
    "    for rgb, depth_target in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        rgb, depth_target = rgb.to(device), depth_target.to(device)\n",
    "\n",
    "        depth_pred = model(rgb)\n",
    "        # print(\"depth_pred,\",depth_pred.shape)\n",
    "        # print(\"depth_target,\",depth_target.shape)\n",
    "        error = calc_error(depth_pred, depth_target)\n",
    "        loss = error[\"loss\"]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        error['loss'] = error['loss'].item()\n",
    "        loss_count.append(error)\n",
    "        loss_arr = [x[\"loss\"] for x in loss_count]\n",
    "        mse_arr = [x[\"MSE\"] for x in loss_count]\n",
    "        rmse_arr = [x[\"RMSE\"] for x in loss_count]\n",
    "        MAE_arr = [x[\"MAE\"] for x in loss_count]\n",
    "        ABS_REL_arr = [x[\"ABS_REL\"] for x in loss_count]\n",
    "        DELTA2_arr = [x[\"DELTA1.02\"] for x in loss_count]\n",
    "        DELTA5_arr = [x[\"DELTA1.05\"] for x in loss_count]\n",
    "\n",
    "        log_str = f\"loss={np.mean(loss_arr):0.8f},MSE={np.mean(mse_arr):0.8f},RMSE={np.mean(rmse_arr):0.8f},MAE={np.mean(MAE_arr):0.8f},ABS_REL={np.mean(ABS_REL_arr):0.8f}, DELTA1.02={np.mean(DELTA2_arr):0.8f}, DELTA1.05={np.mean(DELTA5_arr):0.8f}\"\n",
    "        pbar.set_postfix_str(log_str)\n",
    "\n",
    "\n",
    "def test(model, dataloader, epoch):\n",
    "    time.sleep(0.2)\n",
    "    model.eval()\n",
    "    loss_count = []\n",
    "    pbar = tqdm(dataloader)\n",
    "    pbar.set_description(\"test epoch {}\".format(epoch))\n",
    "    for rgb, depth_target in pbar:\n",
    "        rgb, depth_target = rgb.to(device), depth_target.to(device)\n",
    "        with torch.no_grad():\n",
    "            depth_pred = model(rgb)\n",
    "            error = calc_error(depth_pred, depth_target)\n",
    "\n",
    "        error['loss'] = error['loss'].item()\n",
    "        loss_count.append(error)\n",
    "        loss_arr = [x[\"loss\"] for x in loss_count]\n",
    "        mse_arr = [x[\"MSE\"] for x in loss_count]\n",
    "        rmse_arr = [x[\"RMSE\"] for x in loss_count]\n",
    "        MAE_arr = [x[\"MAE\"] for x in loss_count]\n",
    "        ABS_REL_arr = [x[\"ABS_REL\"] for x in loss_count]\n",
    "        DELTA2_arr = [x[\"DELTA1.02\"] for x in loss_count]\n",
    "        DELTA5_arr = [x[\"DELTA1.05\"] for x in loss_count]\n",
    "        log_str = f\"loss={np.mean(loss_arr):0.8f},MSE={np.mean(mse_arr):0.8f},RMSE={np.mean(rmse_arr):0.8f},MAE={np.mean(MAE_arr):0.8f},ABS_REL={np.mean(ABS_REL_arr):0.8f}, DELTA1.02={np.mean(DELTA2_arr):0.8f}, DELTA1.05={np.mean(DELTA5_arr):0.8f}\"\n",
    "        pbar.set_postfix_str(log_str)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset_train = NyuDataset(mode=\"train\")\n",
    "    dataset_test = NyuDataset(mode=\"test\")\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "    dataloader_test = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "    model = BiSeNetV1()\n",
    "    # model.load_state_dict(torch.load(\"./model_1/model_v1.pth\", map_location=\"cpu\"))\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    for epoch in range(100):\n",
    "        train(model, dataloader_train, epoch, optimizer)\n",
    "        test(model, dataloader_test, epoch)\n",
    "\n",
    "        model.eval()\n",
    "        torch.save(model.state_dict(), f\"./model_1/model_{epoch}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d808852-4f15-49b5-8495-b58dddee9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.save(model.state_dict(), f\"./model_1/model_v1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b4b16-4407-4e86-ab4e-7ba2ce045208",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef35b6-ecdf-468c-94aa-237064ae6b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
