{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66db6f5d-f2d8-42d7-8fa6-afc400d40b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset train with sample number 64824\n",
      "dataset test with sample number 3080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 0: 100%|██████████| 8103/8103 [2:24:39<00:00,  1.07s/it, loss=0.00012583,MSE=0.00165993,RMSE=0.04012409,MAE=0.01413243,ABS_REL=0.00410362,DELTA1.02=0.95942058,DELTA1.05=0.98908504]  \n",
      "test epoch 0: 100%|██████████| 385/385 [02:18<00:00,  2.78it/s, loss=0.00011121,MSE=0.00150803,RMSE=0.03836651,MAE=0.01345236,ABS_REL=0.00381847,DELTA1.02=0.96408651,DELTA1.05=0.98984460]\n",
      "train epoch 1: 100%|██████████| 8103/8103 [2:24:34<00:00,  1.07s/it, loss=0.00010477,MSE=0.00138307,RMSE=0.03604351,MAE=0.01213178,ABS_REL=0.00350645,DELTA1.02=0.96862254,DELTA1.05=0.99178981]  \n",
      "test epoch 1: 100%|██████████| 385/385 [02:20<00:00,  2.75it/s, loss=0.00007760,MSE=0.00104721,RMSE=0.03187641,MAE=0.01069824,ABS_REL=0.00305733,DELTA1.02=0.97369308,DELTA1.05=0.99314845]\n",
      "train epoch 2: 100%|██████████| 8103/8103 [2:24:36<00:00,  1.07s/it, loss=0.00009082,MSE=0.00119573,RMSE=0.03370765,MAE=0.01123372,ABS_REL=0.00323854,DELTA1.02=0.97234880,DELTA1.05=0.99295590]  \n",
      "test epoch 2: 100%|██████████| 385/385 [02:18<00:00,  2.77it/s, loss=0.00006945,MSE=0.00093699,RMSE=0.03017661,MAE=0.01001901,ABS_REL=0.00286049,DELTA1.02=0.97591213,DELTA1.05=0.99387231]\n",
      "train epoch 3:   1%|▏         | 109/8103 [02:03<2:31:14,  1.14s/it, loss=0.00008889,MSE=0.00119411,RMSE=0.03366876,MAE=0.01136629,ABS_REL=0.00324885,DELTA1.02=0.97146808,DELTA1.05=0.99288845]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19281/639516568.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19281/639516568.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, epoch, optimizer)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from util_model_v2 import DepthCompletionModule\n",
    "import torchvision.transforms.functional as ttf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "batch_size = 8\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "min_depth = 0.5\n",
    "max_depth = 7\n",
    "min_dense_ratio = 0.15 / 100\n",
    "max_dense_ratio = 0.5 / 100\n",
    "test_dense_ratio = 0.2 / 100\n",
    "\n",
    "\n",
    "class NyuDataset(Dataset):\n",
    "    def __init__(self, mode=\"train\"):\n",
    "        assert mode == \"train\" or mode == \"test\"\n",
    "        self.mode = mode\n",
    "        files = [str(x) for x in Path(\"./data\").glob(\"*.json\")]\n",
    "        train_files, test_files = train_test_split(files, test_size=0.05, random_state=0)\n",
    "        self.files = train_files if self.mode == \"train\" else test_files\n",
    "        self.dataset = []\n",
    "        for file_path in self.files:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                self.dataset.extend(json.load(f)[::7])\n",
    "        self.dataset_length = len(self.dataset)\n",
    "        self.dataset_length -= self.dataset_length % batch_size\n",
    "        print(f\"dataset {self.mode} with sample number {self.dataset_length}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def read_pgm(pgm_file_path):\n",
    "        with open(pgm_file_path, 'rb') as pgm_file:\n",
    "            p5, width, height, depth = pgm_file.readline().split()\n",
    "            assert p5 == b'P5'\n",
    "            assert depth == b'65535'\n",
    "            width, height = int(width), int(height)\n",
    "            data = np.fromfile(pgm_file, dtype='<u2', count=width * height)\n",
    "            data = data.reshape([height, width]).astype(np.uint32)\n",
    "            return Image.fromarray(data, mode=\"I\")\n",
    "\n",
    "    @staticmethod\n",
    "    def read_ppm(ppm_file_path):\n",
    "        with open(ppm_file_path, 'rb') as ppm_file:\n",
    "            p6, width, height, depth = ppm_file.readline().split()\n",
    "            assert p6 == b'P6'\n",
    "            assert depth == b'255'\n",
    "            width, height = int(width), int(height)\n",
    "            data = np.fromfile(ppm_file, dtype=np.uint8, count=width * height * 3)\n",
    "            data = data.reshape([height, width, 3])\n",
    "            return Image.fromarray(data, mode=\"RGB\")\n",
    "\n",
    "    def transform_fn(self, rgb, depth):\n",
    "        if self.mode == \"train\":\n",
    "            if np.random.uniform() < 0.5:\n",
    "                rgb = ttf.hflip(rgb)\n",
    "                depth = ttf.hflip(depth)\n",
    "\n",
    "            # degree = np.random.uniform(-5.0, 5.0)\n",
    "            # rgb = ttf.rotate(rgb, degree)\n",
    "            # depth = ttf.rotate(depth, degree)\n",
    "\n",
    "            brightness = np.random.uniform(0.9, 1.1)\n",
    "            contrast = np.random.uniform(0.9, 1.1)\n",
    "            saturation = np.random.uniform(0.9, 1.1)\n",
    "            rgb = ttf.adjust_brightness(rgb, brightness)\n",
    "            rgb = ttf.adjust_contrast(rgb, contrast)\n",
    "            rgb = ttf.adjust_saturation(rgb, saturation)\n",
    "\n",
    "        rgb = ttf.to_tensor(rgb)\n",
    "        depth = ttf.to_tensor(depth)\n",
    "        rgb = torch.as_tensor(rgb, dtype=torch.float)\n",
    "        depth = torch.as_tensor(depth, dtype=torch.float)\n",
    "        depth /= 256\n",
    "        depth[depth < min_depth] = 0\n",
    "        depth[depth > max_depth] = 0\n",
    "\n",
    "        rgb = ttf.normalize(rgb, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        return rgb, depth\n",
    "\n",
    "    def generate_sparse_depth(self, full_depth, num_sample):\n",
    "        idx_candidate = torch.nonzero(full_depth > 1e-2)\n",
    "        idx_sample = torch.randperm(len(idx_candidate))[:num_sample]\n",
    "        idx_selected = idx_candidate[idx_sample]\n",
    "        mask = torch.zeros_like(full_depth)\n",
    "        mask[idx_selected[:, 0], idx_selected[:, 1], idx_selected[:, 2]] = 1.\n",
    "        sparse_depth = mask * full_depth\n",
    "        return sparse_depth\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset[idx]\n",
    "        try:\n",
    "            rgb = self.read_ppm(sample[\"ppm\"])\n",
    "            depth = self.read_pgm(sample[\"pgm\"])\n",
    "            rgb, depth = self.transform_fn(rgb, depth)\n",
    "            if self.mode == \"train\":\n",
    "                num_sample = int(np.random.uniform(480 * 640 * min_dense_ratio, 480 * 640 * max_dense_ratio))\n",
    "            else:\n",
    "                num_sample = int(480 * 640 * test_dense_ratio)\n",
    "            sparse_depth = self.generate_sparse_depth(depth, num_sample=num_sample)\n",
    "        except Exception as e:\n",
    "            rgb = torch.zeros([3, 480, 640])\n",
    "            depth = torch.zeros([1, 480, 640])\n",
    "            sparse_depth = torch.zeros([1, 480, 640])\n",
    "        return rgb, sparse_depth, depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_length\n",
    "\n",
    "\n",
    "def calc_error(depth_pred, depth_target):\n",
    "    error = {}\n",
    "    mask = torch.logical_and(torch.gt(depth_target, min_depth), torch.lt(depth_target, max_depth))\n",
    "    depth_pred = depth_pred[mask]\n",
    "    depth_target = depth_target[mask]\n",
    "    n_valid_element = depth_target.shape[0] + 1e-4\n",
    "\n",
    "    diff_mat = torch.abs(depth_pred - depth_target)\n",
    "    rel_mat = torch.div(diff_mat, depth_target)\n",
    "    error[\"MSE\"] = torch.sum(torch.pow(diff_mat, 2)) / n_valid_element\n",
    "    error[\"RMSE\"] = torch.sqrt(error[\"MSE\"])\n",
    "    error['MAE'] = torch.sum(diff_mat) / n_valid_element\n",
    "    error['ABS_REL'] = torch.sum(rel_mat) / n_valid_element\n",
    "    y_over_z = torch.div(depth_target, depth_pred)\n",
    "    z_over_y = torch.div(depth_pred, depth_target)\n",
    "    max_ratio = torch.max(y_over_z, z_over_y)\n",
    "    error['DELTA1.02'] = torch.sum(max_ratio < 1.02) / float(n_valid_element)\n",
    "    error['DELTA1.05'] = torch.sum(max_ratio < 1.05) / float(n_valid_element)\n",
    "\n",
    "    error = {K: V.item() for K, V in error.items()}\n",
    "    error['loss'] = F.mse_loss(torch.sqrt(depth_pred), torch.sqrt(depth_target))\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "def train(model, dataloader, epoch, optimizer):\n",
    "    time.sleep(0.2)\n",
    "    model.train()\n",
    "    loss_count = deque([], maxlen=100)\n",
    "    pbar = tqdm(dataloader)\n",
    "    pbar.set_description(\"train epoch {}\".format(epoch))\n",
    "    for rgb, sparse_depth, depth_target in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        rgb, sparse_depth, depth_target = rgb.to(device), sparse_depth.to(device), depth_target.to(device)\n",
    "        depth_pred = model(rgb, sparse_depth)\n",
    "        error = calc_error(depth_pred, depth_target)\n",
    "        loss = error[\"loss\"]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        error['loss'] = error['loss'].item()\n",
    "        loss_count.append(error)\n",
    "        loss_arr = [x[\"loss\"] for x in loss_count]\n",
    "        mse_arr = [x[\"MSE\"] for x in loss_count]\n",
    "        rmse_arr = [x[\"RMSE\"] for x in loss_count]\n",
    "        MAE_arr = [x[\"MAE\"] for x in loss_count]\n",
    "        ABS_REL_arr = [x[\"ABS_REL\"] for x in loss_count]\n",
    "        DELTA2_arr = [x[\"DELTA1.02\"] for x in loss_count]\n",
    "        DELTA5_arr = [x[\"DELTA1.05\"] for x in loss_count]\n",
    "\n",
    "        log_str = f\"loss={np.mean(loss_arr):0.8f},MSE={np.mean(mse_arr):0.8f},RMSE={np.mean(rmse_arr):0.8f},MAE={np.mean(MAE_arr):0.8f},ABS_REL={np.mean(ABS_REL_arr):0.8f},DELTA1.02={np.mean(DELTA2_arr):0.8f},DELTA1.05={np.mean(DELTA5_arr):0.8f}\"\n",
    "        pbar.set_postfix_str(log_str)\n",
    "\n",
    "\n",
    "def test(model, dataloader, epoch):\n",
    "    time.sleep(0.2)\n",
    "    model.eval()\n",
    "    loss_count = []\n",
    "    pbar = tqdm(dataloader)\n",
    "    pbar.set_description(\"test epoch {}\".format(epoch))\n",
    "    for rgb, sparse_depth, depth_target in pbar:\n",
    "        rgb, sparse_depth, depth_target = rgb.to(device), sparse_depth.to(device), depth_target.to(device)\n",
    "        with torch.no_grad():\n",
    "            depth_pred = model(rgb, sparse_depth)\n",
    "            error = calc_error(depth_pred, depth_target)\n",
    "\n",
    "        error['loss'] = error['loss'].item()\n",
    "        loss_count.append(error)\n",
    "        loss_arr = [x[\"loss\"] for x in loss_count]\n",
    "        mse_arr = [x[\"MSE\"] for x in loss_count]\n",
    "        rmse_arr = [x[\"RMSE\"] for x in loss_count]\n",
    "        MAE_arr = [x[\"MAE\"] for x in loss_count]\n",
    "        ABS_REL_arr = [x[\"ABS_REL\"] for x in loss_count]\n",
    "        DELTA2_arr = [x[\"DELTA1.02\"] for x in loss_count]\n",
    "        DELTA5_arr = [x[\"DELTA1.05\"] for x in loss_count]\n",
    "        log_str = f\"loss={np.mean(loss_arr):0.8f},MSE={np.mean(mse_arr):0.8f},RMSE={np.mean(rmse_arr):0.8f},MAE={np.mean(MAE_arr):0.8f},ABS_REL={np.mean(ABS_REL_arr):0.8f},DELTA1.02={np.mean(DELTA2_arr):0.8f},DELTA1.05={np.mean(DELTA5_arr):0.8f}\"\n",
    "        pbar.set_postfix_str(log_str)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset_train = NyuDataset(mode=\"train\")\n",
    "    dataset_test = NyuDataset(mode=\"test\")\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "    dataloader_test = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "    model = DepthCompletionModule()\n",
    "    # model.load_state_dict(torch.load(\"./model_1/model_3.pth\", map_location=\"cpu\"))\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        train(model, dataloader_train, epoch, optimizer)\n",
    "        test(model, dataloader_test, epoch)\n",
    "\n",
    "        model.eval()\n",
    "        torch.save(model.state_dict(), f\"./model_5/model_2_{epoch}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bfcc9d5-8b89-4606-8688-324db82484a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth_predict torch.Size([4, 1, 480, 640])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "class ResnetBackBone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResnetBackBone, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        self.conv_1 = resnet.layer1\n",
    "        self.conv_2 = resnet.layer2\n",
    "        self.conv_3 = resnet.layer3\n",
    "        self.conv_4 = resnet.layer4\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat2 = self.conv_1(x)\n",
    "        feat2 = self.conv_2(feat2)\n",
    "        feat4 = self.conv_3(feat2)\n",
    "        feat8 = self.conv_4(feat4)\n",
    "        return feat2, feat4, feat8\n",
    "\n",
    "\n",
    "class CovBnRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1):\n",
    "        super(CovBnRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttentionRefinementModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(AttentionRefinementModule, self).__init__()\n",
    "        self.conv_1 = CovBnRelu(in_channels, out_channels)\n",
    "        self.conv_attention = nn.Conv2d(out_channels, out_channels, kernel_size=1, padding=0, bias=False)\n",
    "        self.bn_attention = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.conv_1(x)\n",
    "        atten = torch.mean(feat, dim=(2, 3), keepdim=True)\n",
    "        atten = self.conv_attention(atten)\n",
    "        atten = self.bn_attention(atten)\n",
    "        atten = torch.sigmoid(atten)\n",
    "        out = torch.mul(feat, atten)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DecovBnRelu(nn.Module):\n",
    "    def __init__(self, in_channels_up, in_channels_encoder, out_channels):\n",
    "        super(DecovBnRelu, self).__init__()\n",
    "        self.conv_1 = nn.ConvTranspose2d(in_channels_up, in_channels_up // 2, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv_2 = AttentionRefinementModule(in_channels_up // 2 + in_channels_encoder, out_channels)\n",
    "\n",
    "    def forward(self, x_up, x_encoder):\n",
    "        x = torch.cat([self.conv_1(x_up), x_encoder], dim=1)\n",
    "        x = self.conv_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DepthEstimationModule(nn.Module):\n",
    "    def __init__(self, kernel_size=5):\n",
    "        super(DepthEstimationModule, self).__init__()\n",
    "        self.conv_rgb = CovBnRelu(3, 64)\n",
    "        self.afm_1 = AttentionRefinementModule(64, 64)\n",
    "        self.backbone = ResnetBackBone()\n",
    "        self.conv_8_16 = CovBnRelu(512, 512, stride=2)\n",
    "\n",
    "        self.decoder_16_8 = DecovBnRelu(in_channels_up=512, in_channels_encoder=512, out_channels=256)\n",
    "        self.decoder_8_4 = DecovBnRelu(in_channels_up=256, in_channels_encoder=256, out_channels=128)\n",
    "        self.decoder_4_2 = DecovBnRelu(in_channels_up=128, in_channels_encoder=128, out_channels=64)\n",
    "        self.decoder_2_1 = DecovBnRelu(in_channels_up=64, in_channels_encoder=64, out_channels=128)\n",
    "\n",
    "        self.out_layer_depth = nn.Conv2d(128, 1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, rgb):\n",
    "        feat1 = self.conv_rgb(rgb)\n",
    "        feat1 = self.afm_1(feat1)\n",
    "        feat2, feat4, feat8 = self.backbone(feat1)\n",
    "        feat16 = self.conv_8_16(feat8)\n",
    "        feat8_up = self.decoder_16_8(feat16, feat8)\n",
    "        feat4_up = self.decoder_8_4(feat8_up, feat4)\n",
    "        feat2_up = self.decoder_4_2(feat4_up, feat2)\n",
    "        feat_out = self.decoder_2_1(feat2_up, feat1)  # torch.Size([4, 128, 480, 640])\n",
    "\n",
    "        coarse_depth = self.out_layer_depth(feat_out)\n",
    "        coarse_depth = torch.exp(coarse_depth)  # torch.Size([4, 1, 480, 640])\n",
    "        return coarse_depth\n",
    "\n",
    "\n",
    "class DepthCompletionModule(nn.Module):\n",
    "    def __init__(self, kernel_size=5):\n",
    "        super(DepthCompletionModule, self).__init__()\n",
    "        self.conv_rgb = CovBnRelu(3, 48)\n",
    "        self.conv_depth = CovBnRelu(1, 16)\n",
    "        self.afm_1 = AttentionRefinementModule(64, 64)\n",
    "        self.backbone = ResnetBackBone()\n",
    "        self.conv_8_16 = CovBnRelu(512, 512, stride=2)\n",
    "\n",
    "        self.decoder_16_8 = DecovBnRelu(in_channels_up=512, in_channels_encoder=512, out_channels=256)\n",
    "        self.decoder_8_4 = DecovBnRelu(in_channels_up=256, in_channels_encoder=256, out_channels=128)\n",
    "        self.decoder_4_2 = DecovBnRelu(in_channels_up=128, in_channels_encoder=128, out_channels=64)\n",
    "        self.decoder_2_1 = DecovBnRelu(in_channels_up=64, in_channels_encoder=64, out_channels=128)\n",
    "\n",
    "        self.out_layer_depth = nn.Conv2d(128, 1, kernel_size=3, stride=1, padding=1)\n",
    "        self.out_layer_affinity = nn.Conv2d(128, kernel_size * kernel_size, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.layer_unfold = nn.Unfold(kernel_size=kernel_size, dilation=1, padding=kernel_size // 2)\n",
    "\n",
    "    def forward(self, rgb, sparse_depth):\n",
    "        feat1 = torch.cat([self.conv_rgb(rgb), self.conv_depth(sparse_depth)], dim=1)\n",
    "        feat1 = self.afm_1(feat1)\n",
    "        feat2, feat4, feat8 = self.backbone(feat1)\n",
    "        feat16 = self.conv_8_16(feat8)\n",
    "        feat8_up = self.decoder_16_8(feat16, feat8)\n",
    "        feat4_up = self.decoder_8_4(feat8_up, feat4)\n",
    "        feat2_up = self.decoder_4_2(feat4_up, feat2)\n",
    "        feat_out = self.decoder_2_1(feat2_up, feat1)  # torch.Size([4, 128, 480, 640])\n",
    "\n",
    "        coarse_depth = self.out_layer_depth(feat_out)\n",
    "        affinity = self.out_layer_affinity(feat_out)\n",
    "        coarse_depth = torch.exp(coarse_depth)  # torch.Size([4, 1, 480, 640])\n",
    "        affinity = torch.softmax(affinity, dim=1)  # torch.Size([4, 25, 480, 640])\n",
    "\n",
    "        # stage 2\n",
    "        mask = torch.gt(sparse_depth, 1e-3).float()\n",
    "        refined_depth = coarse_depth\n",
    "        for i in range(12):\n",
    "            refined_depth = mask * sparse_depth + (1 - mask) * refined_depth\n",
    "            depth_unfolded = self.layer_unfold(refined_depth).reshape(affinity.shape)\n",
    "            depth_unfolded = depth_unfolded * affinity\n",
    "            refined_depth = torch.sum(depth_unfolded, dim=1, keepdim=True)\n",
    "\n",
    "        return refined_depth\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    batch_size = 4\n",
    "    model = DepthCompletionModule()\n",
    "    rgb = torch.randn([batch_size, 3, 480, 640])\n",
    "    sparse_depth = torch.randn([batch_size, 1, 480, 640])\n",
    "    depth_predict = model(rgb, sparse_depth)\n",
    "    print(\"depth_predict\", depth_predict.shape)\n",
    "\n",
    "    # torch.save(model.state_dict(), f\"./model_v2.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28d92a0e-fcdd-45b4-a942-a7e9161840a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 19 08:46:16 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.27       Driver Version: 465.27       CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA Tesla V1...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    35W / 250W |  29235MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cdf5c2-f466-4857-825e-83b19025f508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
